# Pinecone and Vector embedding

| Term             | Definition                                                   |
| ---------------- | ------------------------------------------------------------ |
| Pinecone         | A managed **vector database** service designed for fast and scalable similarity search over vector embeddings (like from OpenAI or other ML models). |
| Vector Embedding | A long array of numbers (usually floats) that represents the meaning of a piece of text in high-dimensional space |

Ex of Vector Embedding

```text
"Cats are cute" â†’ turns into: [0.1, -0.03, 0.5, 0.88, ..., 0.002] // (e.g., 1536 numbers)
```

Texts that are semantically similar will have embeddings that are **closer together** in that space. It easier for machines to compare numbers vs actual text.

## Why OpenAi?

OpenAI provides state of the art embedding models (Im using `text-embedding-3 small` because its fast and cheap)

What does the model do?

- Takes a string of text
- Returns a vector embedding
- Ensures **semencitc similarity** is preserved ie: "a cat" and "a small feline" produce similar embeddings.

These models are trained on massive corpora, so they "understand" meaning at a deep level.

### Why cant Pinecone do this itself?

- Pinecone is a vector db it does not generate embeddings it only:
  - Stores vectors
  - Indexes them efficiently
  - Performs fast similarity search
  - It assumes **you'll bring your own embeddings**, generated by a model like OpenAI, Cohere, HuggingFace, etc.